#!/usr/bin/env python
# -*- coding: utf-8 -*-

import re
import argparse
from pathlib import Path

import numpy as np

from tqdm import tqdm

import torch
import torch.nn.functional as F
import torch.utils.data as data

from extractorch import get_cnn
from extractorch.dataset import ImageFolderDataset

# This script uses the PyTorch's pre-trained ResNet-50 CNN to extract
#   res4f_relu convolutional features of size 1024x14x14
#   avgpool features of size 2048D
# We reproduced ImageNet val set Top1/Top5 accuracy of 76.1/92.8 %
# as reported in the following web page before extracting the features:
#   http://pytorch.org/docs/master/torchvision/models.html
#
# We save the final files as 16-bit floating point tensors to reduce
# the size by 2x. We confirmed that this does not affect the above accuracy.
#
# Organization of the image folder:
#  In order to extract features from an arbitrary set of images,
#  you need to create a folder with a file called `index.txt` in it that
#  lists the filenames of the raw images in an ordered way.
#    -f /path/to/images/train  --> train folder contains 29K images
#                                  and an index.txt with 29K lines.
#


def normalize(x):
    """Apply L2-normalization over features."""
    if x.dim() == 2:
        return F.normalize(x, dim=-1)
    else:
        n, c, h, w = x.shape
        return F.normalize(x.view(n, c, -1), dim=1).view(n, c, h, w)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(prog='extractor')
    parser.add_argument('-f', '--folder', type=str, required=True,
                        help='Folder to image files i.e. /images/train')
    parser.add_argument('-b', '--batch-size', type=int, default=256,
                        help='Batch size for forward pass.')
    parser.add_argument('-c', '--central-fraction', type=float, default=1.0,
                        help='Central fraction. If < 1, focuses on the middle.')
    parser.add_argument('-w', '--width', type=int, default=224,
                        help='Final image width and height.')
    parser.add_argument('-m', '--model', type=str, default='resnet50:res5c_relu',
                        help='<model_name:layer> e.g. resnet50:res5c_relu')
    parser.add_argument('-d', '--device', default='cpu',
                        help='cpu or gpu')

    # Parse arguments
    args = parser.parse_args()
    root = Path(args.folder)
    split = root.name
    bs = args.batch_size

    args.device = 'cuda' if args.device == 'gpu' else 'cpu'

    # Disable gradient tracking
    torch.set_grad_enabled(False)

    resize_width = int(args.width / args.central_fraction)
    print('Resize shortest side to {} then center crop {}x{}'.format(
        resize_width, args.width, args.width))

    # Create dataset
    dataset = ImageFolderDataset(
        root.parent, split, resize=resize_width, crop=args.width)
    print('Root folder: {} (split: {}) ({} images)'.format(
        root, split, len(dataset)))
    n_batches = int(np.ceil(len(dataset) / bs))

    # Create data loader
    loader = data.DataLoader(dataset, batch_size=args.batch_size)

    # Create model
    model_type, *layer_type = args.model.lower().split(':')
    layer_type = '' if len(layer_type) == 0 else layer_type[0]
    if model_type == 'alexnet':
        print('INFO: Alexnet only extracts from last conv layer.')
        model = get_cnn('alexnet')()
        layer_type = 'lastconv'
    elif model_type.startswith('resnet'):
        model = get_cnn('resnet')(
            model_type=model_type, layer_type=layer_type)
    elif model_type.startswith(('vgg', 'densenet')):
        print('INFO: {} only extracts from last conv layer.'.format(model_type))
        model_prefix = re.search('([a-z]*)([0-9]*)', model_type)[1]
        layer_type = 'lastconv'
        model = get_cnn(model_prefix)(model_type=model_type)

    # Do not L2-normalize probabilities
    normalize_fn = normalize if layer_type != 'prob' else lambda x: x

    # Create placeholder tensor
    feats = np.zeros(
        (len(dataset), *model.output_shape(args.width, args.width)))
    print('Output tensor shape:', feats.shape)

    ######################
    # Main extraction loop
    ######################
    model.set_device(args.device)
    for bidx, batch in enumerate(tqdm(loader, unit='batch', ncols=70)):
        # Get the activations and normalize
        feats[bidx * bs: (bidx + 1) * bs] = normalize_fn(
            model(batch.to(device=args.device))).data.to('cpu')

    ###############
    # Save the file
    ###############
    output = "{}-{}-{}-r{}-c{}".format(
        split, model_type, layer_type, resize_width, args.width)
    if layer_type != 'prob':
        output += '-l2norm'
    np.save(output, feats.astype('float16'))
